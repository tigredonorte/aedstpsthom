%	Documentação do Trabalho Prático 0 de AEDSIII
%	@Thompson Moreira Filgueiras
%
%	* Você pode identificar erros de grafia através do seguinte comando linux:
%		aspell --encoding="iso8859-1" -c -t=tex --lang="pt_BR" tp0.tex
%	
%	Tenha cuidado com problemas de codificação, você pode perder muito tempo com isso (ter que reescrever o texto por que os caracteres % acendutados não aparecem corretamento no pdf, por exemplo). Se você usa Vi/Vim, ele identifica a codificação sozinho, em editores do tipo % Kate/Kwrite você pode definir a codificação em Ferramentas/Codificação, escolha a opção Oeste Europeu (iso8859-1).
%	Para compilar o texto utilize o comando make (foi criado um Makefile)
%	Para maiores informações consulte referências sobre Latex

\documentclass[12pt]{article}
\usepackage{sbc-template}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{times,amsmath,epsfig}
\usepackage{graphicx,url}
 \makeatletter
 \newif\if@restonecol
 \makeatother
 \let\algorithm\relax
 \let\endalgorithm\relax 
\usepackage[lined,algonl,ruled]{algorithm2e}
\usepackage{multirow}
\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  

\sloppy

\title{TRABALHO PRÁTICO 2: \\ Árvores de pesquisa Ótima}

\author{Thompson Moreira Filgueiras}

\address{Departamento de Ciência da Computação -- Universidade Federal de Minas Gerais (UFMG)
\email{thom@dcc.ufmg.br}
}

\begin{document} 

\maketitle

\begin{resumo}Este relatório descreve como criar uma árvore de pesquisa ótima atravéz de chaves conhecidas e com a frequência de acesso a estas chaves também conhecidas. Descreve também o funcionamento e o comparativo entre três estratégias de programação para resolver o problema de criar uma árvore de pesquisa ótima. É feita uma análise ao final sobre qual a melhor estratégia a ser adotada para criar este tipo de árvore.
\end{resumo}

\section{INTRODUÇÃO}

Neste trabalho prático foram implementadas três árvores de pesquisa ótima. Ou melhor, três estratégias para montar uma árvore binária simples, que contém em seu nodo apenas o valor da chave. As chaves são conhecidas, e sua frequencia no arquivo de entrada é igual a sua popularidade, que é usada para montar a arvore. As estratégias utilizadas são: tentativa e erro, programação dinâmica e estratégia gulosa. Cada uma tem os prós e os contras, que serão explicados a seguir.

A arvore de pesquisa consiste em uma árvore binária simples, onde cada nodo a esquerda é menor lexigográficamente ao nodo pai que é menor do que o nodo da direita. Uma árvore de pesquisa ótima, rearanja estes nodos, obedecendo as regras citadas acima, contudo ela diminui o tempo de pesquisa para o menor tempo possível. O peso de uma árvore, é calculado somando a multiplicação da altura de cada nodo n pela popularidade deste mesmo nodo.

Uma estratégia tentativa e erro para este problema, consiste em reordenar um vetor de tamanho V qualquer e testar todas as combinações de inserção possíveis deste vetor na árvore. Obviamente este algorítmo é fatorial, o que impede que ele rode com entradas acima de 14 elementos, ou pelo menos rode em tempo hábil.

Uma estratégia gulosa para o problema, consiste em ordenar a entrada colocando os elementos com maior peso no topo da árvore. No entanto é possível provar com contra-exemplo que esta estratégia nem sempre gera uma árvore ótima, mas é a mais rápida de ser implementada.

Uma estratégia de programação dinâmica consiste em calcular a melhor arvore com dois elementos para cada dois elementos adjacentes no vetor, depois calcular a melhor árvore com três elementos adjacentes do vetor utilizando as árvores já calculadas com um e dois elementos, depois calcular a melhor árvore com E + 1 elementos com o restante das árvores já calculadas.

Neste trabalho prático foi implementada uma máquina de busca simples, que consiste em inserir em uma estrutura de dados todas as palavras de vários documentos. No caso específico deste trabalho os documentos inseridos eram randômicos, criados por um processo à parte(thread) durante a execussão do código. Os principais objetivos do trabalho são: implementar uma máquina de busca e utilizar as chamadas pthreads.

	O restante deste relatório é organizado da seguinte forma. A Seção~\ref{trabalhos_relacionados} discute alguns temas relacionados ao trabalho. A Seção~\ref{solucao_proposta} descreve a solução proposta. A Seção~\ref{implementacao} trata de detalhes específicos da implementação do trabalho. A Seção~\ref{avaliacao_experimental} contém a avaliação experimental dos três algorítmos. A Seção~\ref{conclusao} conclui o trabalho comparando os algorítmos.

\section{REFERÊNCIAS RELACIONADAS}
\label{trabalhos_relacionados}

Podemos dividir as referências associadas ao problema estudado e à solução proposta dentre os seguintes grupos:
\begin{itemize}
\item \textbf{Árvore de pesquisa ótima} Técnica utilizada quando se conhece a frequência de acesso das chaves e as chaves que serão pesquisadas, consiste em reorganizar os nodos da árvore com o objetivo de diminuir o tempo de busca.
\end{itemize}

\section{SOLUÇÃO PROPOSTA}
\label{solucao_proposta}

A solução proposta consiste em salvar as palavras do arquivo de entrada em um hash aberto com o tamanho igual ao número de palavras do arquivo, sempre que uma palavra se repete, o número de ocorrências desta palavra no hash é incrementado. Este número de ocorrências é usado para calcular a frequência das palavras. Seja F a frequência de uma palavra tal que F = numero de ocorrências / número de linhas da entrada. Cada índice do hash armazena a chave, o número de ocorrências da chave a popularidade da chave (que é calculada depois que o arquivo inteiro é inserido no hash) e uma variavel de status que marca se a posição está cheia ou vazia. Ao final o hash é transformado em um vetor contínuo (sem elementos vazios) no qual as outras partes do algoritmo podem alterar.

A solução utilizando tentativa e erro, consiste em permutar todos os elementos deste vetor de todas as formas possíveis e para cada forma inserí-la na árvore e medir o peso desta. Para permutar os elementos é criado um vetor de inteiros do tamanho do vetor de elementos. Cada índice deste vetor de inteiros, possui o elemento da n-ésima permutação de um vetor qualquer do mesmo tamanho. Ao final do cálculo deste vetor (chamado de fatoridic) o elemento índice i contém um inteiro que corresponte que corresponde à posição do elemento do vetor original no vetor permutado. Em outras palavras, seja V o vetor inicial, FDic o vetor de inteiros e C o vetor que será a cópia da n-ésima permutação do vetor original: C[i] = V[FDic[i]], com 0 <= i <= N, onde N é o tamanho do vetor V. Feitas as permutações o próximo passo consiste em inserir na árvore binária cada combinação e salvar apenas a mais relevante (menor peso).

A solução utilizando programação dinâmica consiste em primeiramente considerar cada árvore possível com 1 elemento, obviamente esta é uma árvore ótima, depois calcular a árvore ótima com dois elementos adjacentes no vetor (lembrando que não há necessidade de calcular todas as árvores possíveis 2 a 2, pois estaríamos calculando assim árvores redundantes). Depois são calculadas as melhores árvores com i elementos adjacentes no vetor, sempre utilizando as árvores com i -1, i - 2, ... , 1 elementos já calculados. O pressuposto deste algorítmo é que seja uma árvore A qualquer, se cada sub-árvore desta árvore é ótima, então esta árvore também é ótima (princípio da otimalidade). De fato, uma árvore ótima possui sub árvores ótima, o que torna este algorítmo um dos mais eficientes para cálculo de árvore ótima. A desvantagem deste algoritmo é a complexidade de tempo e espaço que são $O(n3)$ 

A solução usando a eurística gulosa, consiste em ordenar os elementos do vetor original de tal forma que os elementos inseridos primeiro sejam aqueles com maior peso. Esta estrátégia tem a vantagem de calcular esta árvore com complexidade $O(nlogn)$,  o que o torna mais rápido. No entanto a desvantagem deste algoritmo consiste no fato de que as árvores que ele gera não são ótimas. Contra exemplo: sejam A, B e C três palavras a serem inseridas, com popularidades 1, 0.8, 0.6 respectivamente. A estratégia gulosa criaria uma árvore com peso = 1x0 + 0.8x1 + 0.6x2 = 2. A árvore ótima neste caso consiste na árvore em que B está na raiz e seu peso seria = 0.8x0 + 1x1 + 0.6x1 = 1.6. 

Calculadas as árvores, o programa varre uma árvore criada e gera dois vetores que contém a profundidade de um nodo i e a chave deste mesmo nodo, Esta chave é pesquisada no hash na qual encontra-se a popularidade da palavra, neste caso multiplica-se a profundidade do nodo i x popularidade, soma isto para todos os nodos e obtém-se o peso da árvore. Com estes dois vetores ainda é possível imprimir a saída com a altura do seu nodo correspondente, e o maior nodo é a altura da árvore.  

A seguir, serão descritas as estruturas de dados e algoritmos propostos, assim como a análise de complexidade dos algoritmos:
\subsection{Estruturas de dados}

\subsubsection{Hash Aberto} 
O hash possui seu tamanho, numero de linhas e numero de itens inseridos, além de um vetor de itens.

Cada item possui uma chave, um número de ocorrências, a popularidade (pularidade = numero total de ocorrencias/ numero de linhas) e o status = CHEIO, VAZIO, ESVAZIADO

\subsubsection{Arvore} 
Uma arvore é na realidade um nodo com nome especial, cada nodo possui um elemento da esquerda e um da direita e sua chave.

\subsubsection{Programação Dinâmica} 
Possui uma pilha, na qual cada elemento a ser empilhado são as coordenadas x, y que contem a arvore ótima da matriz A.


\subsection{Algoritmos}

\subsubsection{Hash Aberto} 

Armazena as palavras do arquivo de entrada. Como o número de palavras é conhecido (o arquivo é fixo), a solução de conflitos consiste em inserir na próxima posição vazia. Esta função é $O(1 + N/M)$ onde N é o número de palavras distintas do texto e M o número todal de palavras. Algoritmo de insercao:
\begin{algorithm}[h!]
\begin{footnotesize}

\Insere(Hash, chave)
{
	id = H(chave);
	\SE(Hash[id].chave != chave \ou Hash[id] = vazio)
	{
		\ENQUANTO(Hash[id] = oculpado)
		{
			id = (id +1)MOD(M)
			\SE(Percorreu o vetor inteiro)
			{
				retorne
			}
		}
		Hash[id].chave = chave
		Hash[id].ocorrencias++;
	}
	\SE(Hash[id].chave = chave)
	{
		Hash[id].ocorrencias++;
	}
}

\end{footnotesize}
\end{algorithm}

O algoritmo de pesquisa é semelhante ao de inserção, só que ele procura pelo elemento enquanto não encontrar uma posição vazia ou o próprio elemento.

\subsubsection{Arvore:} 

A arvore binária obedece somente uma regra, a chave da direita é sempre maior do que o pai que é sempre maior do que a chave da esquerda. Os algoritmos de inserção e pesquisa são recursivos, uma vez que partimos do pressuposto que uma árvore binária estará perto de balanceada e esta recursão será no melhor caso $O(log n)$ chamadas recursivas. Embora uma árvore binária possa se tornar em um caso degenerado uma lista encadeada tendo complexidade $O(n)$ para inserção e pesquisa. Como esta árvore é de pesquisa ótima, ela tem que permitir casos em que ela esteja desbalanceada, o que corre o risco da complexidade deste algoritmo realmente vir a atingir um caso degenerado. Seja o algoritmo de insercao:
\begin{algorithm}[h!]
\begin{footnotesize}

\insereNodo(nodo, chave)
{
	\se(nodo = vazio)
	{
		nodo.chave = chave;
	}
	\se(chave > nodo.chave)
	{
		insereNodo(nodo.direita, chave);
	}
	\se(chave < nodo.chave)
	{
		insereNodo(nodo.esquerda, chave);
	}
}
	
\end{footnotesize}
\end{algorithm}

O algoritmo de transformação da arvore em vetor consiste em salvar as chaves da esquerda para a direita no vetor, desta forma este vetor estará ordenado. A função também é recursiva e neste caso ela tem ordem de complexidade $O(n)$, pois passará por cada nodo pelo menos uma vez e cada nodo fará duas chamadas da função.

\begin{algorithm}[h!]
\begin{footnotesize}

\TransformaEmVetor(nodo, vetorPalavra, vetorAltura, i)
{
	\se(nodo = vazio)
	{
		retorna;
	}
	\TransformaEmVetor(nodo.esquerda, vetorPalavra, i);
	vetorPalavra[i] = nodo.chave;
	vetorAltura[i] = profundidadeNodo;
	i++;
	\TransformaEmVetor(nodo.direita, vetorPalavra, i);
}
	
\end{footnotesize}
\end{algorithm}


\subsubsection{Tentativa e erro} 

A estratégia tentativa e erro pode ser dividida em duas partes, a primeira é o cálculo do fatoridic, que é um vetor que guarda a k-ésima permutação de um outro vetor de mesmo tamanho, estas alterações sao salvas no vetor Perm de permutações onde o i-ésimo elemento do vetor permutado é o indice guardado pelo i-ézimo elemento do vetor Perm. Veja o código a seguir onde recebe-se o tamanho do vetor a ser permutado e k, que corresponde a k-esima permutação do vetor original. A complexidade desta função é $O(n2)$
\begin{algorithm}[h!]
\begin{footnotesize}

\Factoradic(size, k)
{
	\PARA(j de 1 a Size)
	{
		factoradic[size - j] = k MOD(J);
		k = k/j;
	}
	\PARA(i de 1 a Size)
	{
		Perm[j] = factoradic[j]+1;
		\PARA(j de 1 a Size)
		{
			\SE(Perm[i] > Perm[j])
			{
				perm[j]++;
			}
		}
	}
	
	\return(Perm);
}
	
\end{footnotesize}
\end{algorithm}

A segunda parte deste algoritmo consiste em calcular todas as arvores possiveis. Isto é feito utilizando o vetor perm retornado da função anterior. Se variarmos o K de 0 a size - 1 em um loop externo, teremos todas as permutações do vetor, neste caso é só inserir este vetor na arvore e calcular o peso desta. Se o peso da árvore é a menor possível salve a arvore.

\begin{algorithm}[h!]
\begin{footnotesize}
\ProcuraMelhorArvore(Vetor, size, arvore)
{
	\PARA(k de 1 a Size)
	{
		Perm = Factoradic(size, k);
		
		\PARA(i de 1 a Size)
		{
			vetorCopia[i] = Vetor[Perm[i]];
		}
		\PARA(i de 1 a Size)
		{
			\insereNodo(arvore, vetorCopia[i]);
			\TransformaEmVetor(arvore, vetorPalavra, vetorAltura, 0)
			\PARA(j de 1 a Size)
			{
				\PesquisaHash(elemento, vetorPalavra[i]);
				popularidade = elemento.popularidade
				aux = vetorAltura[j] *popularidade
				\SE(aux < menorPeso)
				{
					salvaMenorArvore(arvore);
					menorPeso = aux;
				}
			}
		}
	}
}
\end{footnotesize}
\end{algorithm}

\subsubsection{Algoritmo Guloso} 

O Algoritmo guloso é bem simples, ele ordena o vetor original de acordo com as popularidades das chaves e insere as maiores popularidades primeiro. Mas apesar de rápida e de quase não demandar espaço esta estratégia nem sempre gera a árvore ótima, como no exemplo do item solução proposta. O algoritmo de ordenação utilizado foi o quickSort, não cabe ao escopo deste trabalho explicar o quicksort, uma vez que é um algoritmo simples e de fácil consulta na web. Apos ordenado o vetor insere os elementos na arvore.

\begin{algorithm}[h!]
\begin{footnotesize}
\insereArvore(Vetor, arvore, size)
{
	\OrdenaQuickSort(vetor);
	\para(i de 1 a size)
	{
		\insereNodo(arvore, Vetor[i])
	}
}
\end{footnotesize}
\end{algorithm}

\subsubsection{Programação Dinâmica} 

Dos três algoritmos implementados a criação de árvores por programação dinâmica é a mais eficiente, pelo fato de calcular sempre uma árvore ótima com complexidade de tempo muito melhor do que fatorial $O(N3)$ e complexidade de espaço $O(N3)$. O algoritmo em si consiste em calcular as melhores sub árvores com 1 elemento, e a partir daí calcular as proximas subarvores baseando-se nas que ja foram calculadas. Para tal, aloca-se uma matriz size x size para calcular estas sub-arvores, a cada iteração aloca-se ainda dois vetores size x1 que guardarão as opções de árvores à esquerda e à direita. Para calcular o peso da sub-arvore é Calculada a melhor sub-arvore da direita e da esquerda somando-se os pesos com o peso do vetor size x size W, que contém a soma dos elementos da subarvore atual. O algoritmo para calcular W é $O(N3)$ em tempo.

\begin{algorithm}[h!]
\begin{footnotesize}
\CalculaW(Vetor, size)
{
	\PARA(i de 1 ate size)
	{
		\PARA(j de i ate size)
		{
			\PARA(k de j-i ate j+1)
			{
				W[i][j] += W[0][k];
			}
		}
	}
}

\CalculaA(A, size)
{
	\CalculaW(W, size);
	\PARA(i de 1 ate size)
	{
		\PARA(j de i ate size)
		{
			\SE(i = j)
			{
				\PARA(k de 1 ate j)
				{
					esq[k+1] = A[k][k];
				}
				z = j - 1;
				\PARA(k de 1 ate j)
				{
					dir[k] = A[z][j];
					z--;
				}
			}
			\SENAO
			{
				n = i - 1;
        			z = j - 1;
				\PARA(k de 1 ate i)
				{
					esq[k] = A[n][z];
					n--;
					z--;
				}
				\PARA(k de 1 ate i)
				{
					dir[k] = A[k-1][j];
				}

				\PARA(k de 1 ate i)
				{
					m = esq[k] + dir[k];
					\SE(menor > m)
					{
					    menor = m;
					}
				}
			}
			
		}
	}
}
\end{footnotesize}
\end{algorithm}


Calculada a matriz, o proximo passo é montar a árvore, para tal foi criada uma pilha de elementos, que inicializa com o elemento da matriz size x size, Cada vez que um item é retirado da pilha empilha-se a sub-arvore ótima da direita do item, salva-se o elemento atual em um vetor de insercao na arvore e empilha-se a sub-arvore da esquerda. Quando uma sub-arvore empilhada é nula (-1) não se realiza nada e é retirado o próximo elemento da pilha.

\criaVetor(A, size, Pilha)
{
	\empilha(pilha, size, size);
	\ENQUANTO(pilha !Vazia)
	{
		\desempilha(pilha, e);
		\SE(e= valido)
		{
			empilha(A[e.x][e.y].direita);
			empilha(A[e.x][e.y].esquerda);
			VMelhor[i] = A[e.x][e.y];
			i++;
		}
	}
}

\section{IMPLEMENTAÇÃO}
\label{implementacao}

\subsection{Código}
\subsubsection{Arquivos .c}

\begin{itemize}
\item \textbf{main.c:} Arquivo principal, ele controla o fluxo de execussão principal.
\item \textbf{file.c:} Define as funções relacionadas a leitura e escrita de arquivos
\item \textbf{arvore.c:} Cria uma arvore binaria.
\item \textbf{hashaberto.c:} Cria um hash com solução de conflito = ao proximo endereço válido
\item \textbf{dinamica.c:} Contém as funções de programação dinâmica.
\item \textbf{guloso.c:} Contém a eurística gulosa para o problema.
\item \textbf{tentativa.c:} Contém o algoritmo de tentativa e erro do problema
\end{itemize}

\subsubsection{Arquivos .h}

\begin{itemize}

\item \textbf{arvore.h:} Define a estrutura da arvore binaria
\item \textbf{hashaberto.h:} Define a estrutura do hash aberto
\item \textbf{dinamica.h:} Define a estrutura de uma pilha

\end{itemize}

\subsection{Compilação}

O programa deve ser compilado através do compilador GCC através de um makefile ou atravéz do seguinte comando:

\begin{footnotesize}
\begin{verbatim} gcc -Wall -lm main.c file.c arvore.c hashaberto.c dinamica.c guloso.c tentativa.c -o tp2 \end{verbatim}
\end{footnotesize}

\subsection{Execução}

A execução do programa tem como parâmetros:
\begin{itemize}
\item Um arquivo de vocabulario.
\item O nome do arquivo de saida.
\item O algoritmo a ser execultado {1, 2 ou 3}
\item Nome do arquivo para salvar as estatisticas(parametro nao obrigatorio)
\end{itemize}

O comando para a execução do programa é da forma:

\begin{footnotesize}
\begin{verbatim} ./tp2 -i<arquivo de entrada> -o <arquivo de saida> -s <algoritmo> -t <arquivo de estatistica> \end{verbatim}
\end{footnotesize}

\subsubsection{Formato da entrada}

O formato da entrada possui n palavras
\begin{footnotesize}
\begin{verbatim}
palavra 1 palavra 2 palavra 3
palavra 4
   .
   .
palavra N
\end{verbatim}
\end{footnotesize}

\subsubsection{Formato da saída}

A saída do programa exibe a palavra inserida, sua popularidade e o nodo no qual a arvore aparece. Exibe ainda o número de nodos na árvore, o custo da árvore e a altura da arvore
exemplo de saida:

\begin{footnotesize}
\begin{verbatim}
palavra1 0.020000 1
palavra2 0.800000 0
palavra1 0.020000 1
3
0.4
1
\end{verbatim}

\section{AVALIAÇÃO EXPERIMENTAL}
\label{avaliacao_experimental}

Para cada entrada, foram testados dez vezes cada algoritmo, desta forma os valores calculados de tempo tendem a ficar mais perto da média do algoritmo. Para cada algoritmo foram realizados 4 testes com entradas diferentes. 

Uma ressalva que deve ser feita, é que para o algoritmo tentativa e erro, as entradas testadas foram com até 8 palavras distintas, isto porque, devido ao custo fatorial do algoritmo.

O algoritmo de programação dinâmica também não roda com arquivos acima de 400 palavras, pois ele é cúbico em relação ao espaco, e neste caso (400)^3 x 28bytes / (1024)^2 = 1.7gb, o que praticamente estoura a memória do computador testado.

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{../graficos/tabela.jpg}
\caption{Gráfico}
\end{figure}

Como podemos ver na tabela, O algoritmo guloso roda mais rapido para entradas bem maiores do que a dos outros algoritmos, assim como o algoritmo programação dinâmica é mais rápido do que o tentativa e erro, que sua vez so rodou com entradas n ate 8.


\section{CONCLUSÃO}
\label{conclusao}

Dos três algoritmos somente dois encontram a árvore ótima: tentativa e erro e programação dinâmica, enquanto a eurística gulosa nem sempre encontra a árvore ótima, mas encontra uma árvore próxima da ótima, a principal vantagem deste é a sua simplicidade de implementação e a velocidade com que ele funciona, pois para uma entrada n, ele tem complexidade de tempo nlogn, que é o custo de ordenar o vetor e mais um custo nlogn para inserir na árvore.

A estratégia tentativa e erro é o algorítmo mais óbvio de se pensar, no entanto a sua implementação foi tão complicada ou mais do que a da programação dinâmica, uma vez que não é trivial encontrar uma forma de permutar um vetor de tal forma que todas as permutações aconteçam. O maior problema dele é sua complexidade de tempo fatorial, que impede que ele seja usado para calcular qualquer coisa.

A programação dinâmica testa as possibilidades mais relevantes do algoritmo tentativa e erro, em outras palavras a programação dinâmica é uma tentativa e erro que memoriza as melhores decisões já tomadas, para cada nova decisão ele leva em conta as decisões que já tomou obedecendo ao princípio da otimalidade, dentre os algoritmos é o que equilibra tempo de execussão e eficiência, pois é o que calcula a árvore ótima com maior velocidade, esta é sua vantagem em relação a estratégia gulosa, pois ela não calcula a árvore ótima

É difícil dizer qual dos dois algoritmos é o melhor, pois muitas vezes queremos uma árvore que seja perto da ótima com o menor tempo possível, pois esta árvore pode aceitar inserções e remoções, neste caso o guloso atende as necessidades. Se esta árvore não aceitar inserções e remoções ou estas ocorrerem com baixa frequência a melhor estratégia é a programação dinâmica. Ou seja, a escolha de um algoritmo neste caso, e na maioria dos outros casos em computação dependem da necessidade daquela aplicação específica.

Algumas melhorias que poderiam ser consideradas neste trabalho são:
\begin{itemize}
\item Utilização de uma função mais eficiente para a programação dinâmica.
\item Utilização de uma estratégia mais esperta, evitando redundâncias para o algoritmo de tentativa e erro, mas neste caso, o melhor que este algorítmo pode ser é fatorial, logo a complexidade do mesmo não será reduzida.
\end{itemize}
\bibliographystyle{sbc}
\bibliography{tp}

\end{document}
